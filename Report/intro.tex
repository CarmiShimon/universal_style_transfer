\begin{Introduction}
	Style transfer aims to synthesize an image that
	preserves some notion of the content but carries characteristics of the style. The key challenge is how to extract effective representations of the style and then match it in the content image.
	Transferring the style from one image onto another can be considered a problem of texture transfer. In texture transfer the goal is to synthesize a texture from a source image while constraining the texture synthesis in order to preserve the semantic content of a target image. For texture synthesis there exist a large range of powerful non-parametric algorithms that can synthesise photo realistic natural textures by re-sampling the pixels of a given source texture [1,2,3,4]. Most previous texture transfer algorithms rely on these non-parametric methods for texture synthesis while using different ways to preserve the structure of the target image. For instance, Efros and Freeman introduce a correspondence map that includes features of the target image such as image intensity to constrain the texture synthesis procedure[3]. Lee et al. improve this algorithm by additionally informing the texture transfer with edge orientation information [5]. Although these algorithms achieve remarkable results, they all suffer from the same fundamental limitation: they use only low-level image features of the target image to inform the texture transfer. Ideally, however, a style transfer algorithm should be able to extract the semantic image content from the target image (e.g. the objects and the general scenery) and then inform a texture transfer procedure to render the semantic content of the target image in the style ofthe source image. Therefore, a fundamental prerequisite isto find image representations that independently model vari-ations in the semantic image content and the style in which12414
	

\end{Introduction}