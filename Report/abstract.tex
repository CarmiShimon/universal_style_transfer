\begin{abstract}
	Style transfer is the technique of recomposing images in the style of other images.
	Universal style transfer aims to transfer arbitrary visual styles to content images.
	Existing feed-forward based techniques would need to be trained on pre-defined styles and then fine tuned for new styles. Whereas, this paper presents new methods which are completely independent of the style during train phase making it a “learning-free” approach.
	In this paper, we present an encoder-decoder architecture where the encoder serves as feature-extractor and the decoder is trained for image reconstruction. 
	The Goal is to build a new Image which has the contents of the Content Image and style of the Style Image.
	Our results provide new insights handling arbitrary styles in an efficient-Learning-free methods.
\end{abstract}
