Existing stylization methods can be classified into two categories: global and local. Global methods [12,13] achieve stylization through matching the means and variances of pixel colors [12]. Local methods [14] stylize images through finding dense correspondences between the content and style photos based on either low-level or high-level features. These approaches are slow in practice. Also, they are often developed for specific scenarios. Therefore these methods do not scale to the setting of arbitrary style images well.\newline
Gatys et al. [7,8] showed remarkable results by using the VGG-19 deep neural network for style transfer. The major step in the algorithm is to solve an optimization problem of matching the Gram matrices of deep features extracted from the content and style photos. A number of methods have been developed [15,16,17] to further improve its stylization performance and speed. However, these methods do not aim for preserving photorealism.\newline
Their approach was taken up by various follow-up papers that, among other things, proposed different  ways  to  represent  the  style  within  the  neural  network. Li et al. [15] suggested an approach to preserve local patterns of the style image. Instead of using a global representation of the style, computed as Gram matrix.\newline
Nikulin et al. [18] tried the style transfer algorithm by Gatys et al. on other nets than VGG and proposed several  variations  in  the  way  the  style  of  the  image  is  represented  to  archive different goals like illumination or season transfer. However, this method is developed for specific scenarios which cannot be scaled to the setting of arbitrary style images.\newline
This work is an extension of [11], which is closest to a related work [19], directly adjusts the content feature to match the mean and variance of the style feature. However, the generalization ability of the learned models on unseen styles is still limited.\newline

Different from the existing methods, our approach performs style transfer efficiently in a feed-forward
manner while achieving generalization and visual quality on arbitrary styles. Our approach is closely
related to [15], where content feature in a particular (higher) layer is adaptively instance normalized
by the mean and variance of style feature. This step can be viewed as a sub-optimal approximation
of the WCT operation, thereby leading to less effective results on both training and unseen styles.
Moreover, our encoder-decoder network is trained solely based on image reconstruction, while [15]
requires learning such a module particularly for stylization task. We evaluate the proposed algorithm
with existing approaches extensively on both style transfer and texture synthesis tasks and present
in-depth analysis.